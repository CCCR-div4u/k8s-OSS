# Prometheus + Grafana + Thanos í†µí•© ì„¤ì •
prometheus:
  prometheusSpec:
    # Thanos Sidecar ì„¤ì •
    thanos:
      image: quay.io/thanos/thanos:v0.32.5
      version: v0.32.5
      objectStorageConfig:
        name: thanos-objstore-config
        key: objstore.yml
    
    # ë°ì´í„° ë³´ì¡´ ê¸°ê°„
    retention: 15d
    
    # ìŠ¤í† ë¦¬ì§€ ì„¤ì •
    storageSpec:
      volumeClaimTemplate:
        spec:
          resources:
            requests:
              storage: 50Gi
          storageClassName: gp3
    
    # ë¦¬ì†ŒìŠ¤ ì„¤ì •
    resources:
      requests:
        memory: 400Mi
        cpu: 100m
      limits:
        memory: 2Gi
        cpu: 1000m

# Grafana ì„¤ì •
grafana:
  # ê´€ë¦¬ì íŒ¨ìŠ¤ì›Œë“œ
  adminPassword: admin123!
  
  # ê¸°ë³¸ ë°ì´í„° ì†ŒìŠ¤ ë¹„í™œì„±í™”
  defaultDashboardsEnabled: false
  
  # ê¸°ë³¸ Prometheus ë°ì´í„°ì†ŒìŠ¤ ë¹„í™œì„±í™”
  sidecar:
    datasources:
      defaultDatasourceEnabled: false
  
  # ì»¤ìŠ¤í…€ ë°ì´í„° ì†ŒìŠ¤ ì„¤ì • (Thanos Query + Direct Prometheus)
  datasources:
    datasources.yaml:
      apiVersion: 1
      datasources:
      - name: Thanos-Query
        type: prometheus
        url: http://thanos-query:9090
        access: proxy
        isDefault: true
        jsonData:
          timeInterval: 30s
      - name: Prometheus-Direct
        type: prometheus
        url: http://monitoring-kube-prometheus-prometheus:9090
        access: proxy
        isDefault: false
        jsonData:
          timeInterval: 15s
  
  # ë¦¬ì†ŒìŠ¤ ì„¤ì •
  resources:
    requests:
      memory: 128Mi
      cpu: 100m
    limits:
      memory: 512Mi
      cpu: 500m
  
  # ì„œë¹„ìŠ¤ ì„¤ì •
  service:
    type: ClusterIP
    port: 80

# AlertManager ì„¤ì •
alertmanager:
  enabled: true
  config:
    global:
      slack_api_url: 'https://hooks.slack.com/services/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'
    
    route:
      group_by: ['alertname', 'instance']
      group_wait: 10s
      group_interval: 10s
      repeat_interval: 1h
      receiver: 'slack-notifications'
    
    inhibit_rules:
    # EKS ê´€ë¦¬í˜• ì»´í¬ë„ŒíŠ¸ ì•Œë¦¼ ì–µì œ
    - target_match:
        alertname: 'KubeSchedulerDown'
    - target_match:
        alertname: 'KubeControllerManagerDown'
    - target_match:
        alertname: 'KubeEtcdDown'
    
    receivers:
    - name: 'null'
    - name: 'slack-notifications'
      slack_configs:
      - channel: '#alert'
        username: 'EKS Monitor'
        title: '{{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts }}
          *íŒŒë“œ/ë…¸ë“œ*: {{ .Labels.instance }}{{ .Labels.node }}{{ .Labels.pod }}
          *ìƒíƒœ*: {{ if .Labels.severity }}{{ .Labels.severity }}{{ else }}warning{{ end }}
          *ê°’*: {{ .Annotations.value }}
          *ì„¤ëª…*: {{ .Annotations.summary }}
          
          ğŸ“Š [Grafana ëŒ€ì‹œë³´ë“œ](https://grafana.bluesunnywings.com)
          ğŸ” [Prometheus ì¿¼ë¦¬](https://prometheus.bluesunnywings.com)
          {{ end }}
        color: '{{ if eq .Status "firing" }}danger{{ else }}good{{ end }}'
  
  alertmanagerSpec:
    resources:
      requests:
        memory: 200Mi
        cpu: 100m
      limits:
        memory: 500Mi
        cpu: 500m